{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "file = open('city_names.txt','r')\n",
    "city_names = file.read().split('\\n')\n",
    "city_names = city_names[:-1] # Removing last empty value in the list\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names_lower = [city.lower() for city in city_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aberdeen', 'Abilene', 'Akron', 'Albany', 'Albuquerque', 'Alexandria', 'Allentown', 'Amarillo', 'Anaheim', 'Anchorage']\n"
     ]
    }
   ],
   "source": [
    "print(city_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spell_checker:\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        file = open(filename,'r')\n",
    "        self.city_names = file.read().split('\\n')\n",
    "        self.city_names = self.city_names[:-1] # Removing last empty value in the list\n",
    "        file.close()\n",
    "        self.city_names_lower = [city.lower() for city in city_names]\n",
    "        self.WORDS = self.city_names_lower\n",
    "\n",
    "    def edits1(self,word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        \n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self,word): \n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n",
    "    \n",
    "    def candidates(self,word): \n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or self.known(self.edits3(word)) or [\"No match found\"])\n",
    "\n",
    "    def known(self,words): \n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in self.WORDS)\n",
    "    \n",
    "    def result(self,word):\n",
    "        output_list = []\n",
    "        for w in self.candidates(word.lower()):\n",
    "            output_list.append(self.city_names[self.city_names_lower.index(w)])\n",
    "        return output_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spellCheck = spell_checker('city_names.txt')\n",
    "word = \"Fort walton bpeach\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fort Walton Beach']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellCheck.result(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fort Walton Beach'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fort walton'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'fort walton'.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2_list = []\n",
    "for e1 in edits1(word.lower()):\n",
    "    for e2 in edits1(e1):\n",
    "        e2_list.append(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fort walton beach\n"
     ]
    }
   ],
   "source": [
    "for w in set(e2_list):\n",
    "    if w in WORDS:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fort wilton bpeach', 'fort wilton bpeacwh', 'fobt wilton bpeach', 'fort wslton bpeach', 'fort vwilton bpeach', 'fort wilton bpeaceh', 'fort wilton bpeachc', 'fort wilton bpaech', 'fort pwilton bpeach', 'fort ilton bpeach', 'fort wiltontbpeach', 'fort wiltonz bpeach', 'forq wilton bpeach', 'fort wilton bveach', 'fort wilton bpeacz', 'fort wilton bpeacyh', 'fort wilton bpreach', 'fort wilton bpeamh', 'fort wilton bpqach', 'fort wplton bpeach', 'fort wilton speach', 'fort wiltxon bpeach', 'fort wilton mpeach', 'fort wiltonb peach', 'fofrt wilton bpeach', 'fortm wilton bpeach', 'forvt wilton bpeach', 'fort wiltcn bpeach', 'fortk wilton bpeach', 'fort wrlton bpeach', 'fortf wilton bpeach', 'fort wilton tbpeach', 'fort wiltvon bpeach', 'fort wiltoy bpeach', 'fort widlton bpeach', 'fort wilhon bpeach', 'forot wilton bpeach', 'fort zwilton bpeach', 'fort willon bpeach', 'fort wiliton bpeach', 'fort witton bpeach', 'fort wilton bdeach', 'fort witon bpeach', 'fortw ilton bpeach', 'flort wilton bpeach', 'bfort wilton bpeach', 'fort wilton bpeich', 'fortfwilton bpeach', 'fort wilton bpeacf', 'fort wilton bpdach', 'fort wilmon bpeach', 'fort wiltonq bpeach', 'fort wilton bpteach', 'foyrt wilton bpeach', 'fort wiltoan bpeach', 'fort wilton bqpeach', 'fort wiltmon bpeach', 'fort wilton bpeachq', 'fort ewilton bpeach', 'fort wibton bpeach', 'fort wioton bpeach', 'fort wiltos bpeach', 'fort wiltron bpeach', 'forqt wilton bpeach', 'fort wdilton bpeach', 'fort wflton bpeach', 'fort wilton qpeach', 'fort wilton opeach', 'fort wilton xpeach', 'fort wilrton bpeach', 'fort wiltoxn bpeach', 'fport wilton bpeach', 'fqort wilton bpeach', 'formt wilton bpeach', 'fort wilton bhpeach', 'fort wilton bpeuch', 'fort wilton bpeacs', 'fort wilton bpebach', 'fort wilton bpenach', 'fort kilton bpeach', 'fgrt wilton bpeach', 'fort bwilton bpeach', 'fort wilton bpdeach', 'ort wilton bpeach', 'fort wilton bpeachs', 'fort wizlton bpeach', 'fort wilton bpeah', 'fort wtlton bpeach', 'fort wilthn bpeach', 'fort wilton kbpeach', 'foat wilton bpeach', 'forrt wilton bpeach', 'fort wilton dbpeach', 'fort wilton bpnach', 'fort wiqton bpeach', 'fortc wilton bpeach', 'fort dwilton bpeach', 'fort iwlton bpeach', 'fort wilton bpeacah', 'fortcwilton bpeach']\n"
     ]
    }
   ],
   "source": [
    "# print(e2_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
